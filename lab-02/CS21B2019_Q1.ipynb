{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True, precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Weight Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.array([[0.5, 1.5, 0.8], [0.8, 0.2, -1.6]])\n",
    "W2 = np.array([[0.9, -1.7, 1.6], [1.2, 2.1, -0.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.array([1.0, 0.7, 1.2])    # feature vector input for first layer\n",
    "X2 = np.array([1.0, 0.0, 0.0])    # input for second layer\n",
    "t = np.array([1.0, 0.0])            # target output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_2_output(y: np.array):\n",
    "    return np.array([1 if i > 0.5 else 0 for i in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Forward Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(feature_vector, weight_vector):\n",
    "    return sigmoid(np.dot(weight_vector, feature_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back Propagation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(W, X, delta_vector, learning_rate):\n",
    "    n, m = W.shape\n",
    "    for j in range(n):\n",
    "        for i in range(m):\n",
    "            W[j, i] = W[j, i] - learning_rate * delta_vector[j] * X[i]\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Vector (Hidden Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_hidden_layer(next_delta_vector, W, output_vector):\n",
    "    n, m = W.shape\n",
    "    delta_vector = np.zeros(m - 1)\n",
    "\n",
    "    for i in range(m - 1):\n",
    "        for j in range(n):\n",
    "            delta_vector[j] += next_delta_vector[i] * W[i , j + 1]\n",
    "\n",
    "    delta_vector = output_vector * (1 - output_vector) * delta_vector\n",
    "    return delta_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(X1, X2, W1, W2, t, learning_rate = 0.001, max_epochs = 1000):\n",
    "     for epoch in range(max_epochs):\n",
    "          print(f\"Epoch {epoch + 1}\")\n",
    "          o1 = feed_forward(X1, W1)\n",
    "          X2[1], X2[2] = o1[0], o1[1]\n",
    "          o2 = feed_forward(X2, W2)\n",
    "          output = sigmoid_2_output(o2)\n",
    "          if(np.array_equal(output, t)):\n",
    "               print(f\"Converged after {epoch + 1} epochs\")\n",
    "               break\n",
    "          else:\n",
    "               delta_2_vector = (o2 - t) * o2 * (1 - o2)\n",
    "               # print(f\"Delta 2: {delta_2_vector}\")\n",
    "               W2 = back_propagation(W2, X2, delta_2_vector, learning_rate)\n",
    "               # print(\"O1 : \", o1)\n",
    "               delta_1_vector = delta_hidden_layer(delta_2_vector, W2, o1)\n",
    "               # print(f\"Delta 1: {delta_1_vector}\")\n",
    "               W1 = back_propagation(W1, X1, delta_1_vector, learning_rate)\n",
    "          print(W1, '\\n\\n' , W2)\n",
    "     else:\n",
    "          print(\"Did not converge after max epochs\")\n",
    "     return W1, W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "[[ 0.4893  1.4925  0.7871]\n",
      " [ 0.8229  0.2161 -1.5725]] \n",
      "\n",
      " [[ 0.9689 -1.6363  1.6188]\n",
      " [ 1.1801  2.0815 -0.2054]]\n",
      "Epoch 2\n",
      "[[ 0.4789  1.4853  0.7747]\n",
      " [ 0.8455  0.2319 -1.5454]] \n",
      "\n",
      " [[ 1.0337 -1.5765  1.6374]\n",
      " [ 1.1593  2.0624 -0.2114]]\n",
      "Epoch 3\n",
      "[[ 0.469   1.4783  0.7628]\n",
      " [ 0.8674  0.2472 -1.5191]] \n",
      "\n",
      " [[ 1.0938 -1.5212  1.6554]\n",
      " [ 1.1377  2.0425 -0.2179]]\n",
      "Epoch 4\n",
      "[[ 0.4595  1.4716  0.7514]\n",
      " [ 0.8884  0.2618 -1.494 ]] \n",
      "\n",
      " [[ 1.1489 -1.4706  1.6727]\n",
      " [ 1.1151  2.0218 -0.225 ]]\n",
      "Epoch 5\n",
      "[[ 0.4504  1.4653  0.7405]\n",
      " [ 0.9082  0.2757 -1.4701]] \n",
      "\n",
      " [[ 1.1991 -1.4246  1.6891]\n",
      " [ 1.0916  2.0002 -0.2327]]\n",
      "Epoch 6\n",
      "[[ 0.4416  1.4591  0.73  ]\n",
      " [ 0.9269  0.2889 -1.4477]] \n",
      "\n",
      " [[ 1.2445 -1.3831  1.7046]\n",
      " [ 1.0669  1.9777 -0.241 ]]\n",
      "Epoch 7\n",
      "[[ 0.4331  1.4532  0.7198]\n",
      " [ 0.9446  0.3012 -1.4265]] \n",
      "\n",
      " [[ 1.2857 -1.3455  1.7191]\n",
      " [ 1.0412  1.9542 -0.2501]]\n",
      "Epoch 8\n",
      "[[ 0.4249  1.4474  0.7099]\n",
      " [ 0.9611  0.3128 -1.4066]] \n",
      "\n",
      " [[ 1.3229 -1.3116  1.7326]\n",
      " [ 1.0142  1.9296 -0.26  ]]\n",
      "Epoch 9\n",
      "[[ 0.4168  1.4417  0.7001]\n",
      " [ 0.9767  0.3237 -1.3879]] \n",
      "\n",
      " [[ 1.3567 -1.281   1.7453]\n",
      " [ 0.9858  1.9039 -0.2706]]\n",
      "Epoch 10\n",
      "[[ 0.4087  1.4361  0.6905]\n",
      " [ 0.9915  0.3341 -1.3702]] \n",
      "\n",
      " [[ 1.3874 -1.2532  1.7572]\n",
      " [ 0.956   1.8769 -0.2821]]\n",
      "Epoch 11\n",
      "[[ 0.4007  1.4305  0.6808]\n",
      " [ 1.0056  0.3439 -1.3533]] \n",
      "\n",
      " [[ 1.4154 -1.2279  1.7683]\n",
      " [ 0.9246  1.8485 -0.2946]]\n",
      "Epoch 12\n",
      "[[ 0.3927  1.4249  0.6712]\n",
      " [ 1.019   0.3533 -1.3372]] \n",
      "\n",
      " [[ 1.441  -1.2048  1.7787]\n",
      " [ 0.8915  1.8186 -0.3081]]\n",
      "Epoch 13\n",
      "[[ 0.3845  1.4192  0.6614]\n",
      " [ 1.032   0.3624 -1.3216]] \n",
      "\n",
      " [[ 1.4644 -1.1836  1.7885]\n",
      " [ 0.8565  1.7872 -0.3226]]\n",
      "Epoch 14\n",
      "[[ 0.3762  1.4134  0.6515]\n",
      " [ 1.0445  0.3712 -1.3066]] \n",
      "\n",
      " [[ 1.4861 -1.1643  1.7977]\n",
      " [ 0.8196  1.754  -0.3383]]\n",
      "Epoch 15\n",
      "[[ 0.3678  1.4075  0.6414]\n",
      " [ 1.0568  0.3798 -1.2918]] \n",
      "\n",
      " [[ 1.506  -1.1464  1.8063]\n",
      " [ 0.7803  1.7189 -0.3554]]\n",
      "Epoch 16\n",
      "[[ 0.3591  1.4014  0.6309]\n",
      " [ 1.0689  0.3882 -1.2773]] \n",
      "\n",
      " [[ 1.5244 -1.1299  1.8145]\n",
      " [ 0.7387  1.6817 -0.3738]]\n",
      "Epoch 17\n",
      "[[ 0.3502  1.3951  0.6202]\n",
      " [ 1.0809  0.3967 -1.2629]] \n",
      "\n",
      " [[ 1.5415 -1.1147  1.8222]\n",
      " [ 0.6945  1.6423 -0.3938]]\n",
      "Epoch 18\n",
      "[[ 0.341   1.3887  0.6091]\n",
      " [ 1.093   0.4051 -1.2484]] \n",
      "\n",
      " [[ 1.5574 -1.1006  1.8296]\n",
      " [ 0.6474  1.6005 -0.4155]]\n",
      "Epoch 19\n",
      "[[ 0.3314  1.382   0.5977]\n",
      " [ 1.1053  0.4137 -1.2337]] \n",
      "\n",
      " [[ 1.5722 -1.0875  1.8365]\n",
      " [ 0.5972  1.5561 -0.4391]]\n",
      "Epoch 20\n",
      "[[ 0.3215  1.3751  0.5858]\n",
      " [ 1.1178  0.4225 -1.2186]] \n",
      "\n",
      " [[ 1.586  -1.0754  1.8431]\n",
      " [ 0.5438  1.5089 -0.4647]]\n",
      "Epoch 21\n",
      "[[ 0.3113  1.3679  0.5735]\n",
      " [ 1.1307  0.4315 -1.2031]] \n",
      "\n",
      " [[ 1.5988 -1.0641  1.8494]\n",
      " [ 0.4869  1.4589 -0.4924]]\n",
      "Epoch 22\n",
      "[[ 0.3007  1.3605  0.5608]\n",
      " [ 1.1442  0.4409 -1.187 ]] \n",
      "\n",
      " [[ 1.6108 -1.0536  1.8553]\n",
      " [ 0.4265  1.406  -0.5224]]\n",
      "Epoch 23\n",
      "[[ 0.2898  1.3529  0.5478]\n",
      " [ 1.1582  0.4508 -1.1701]] \n",
      "\n",
      " [[ 1.622  -1.0438  1.861 ]\n",
      " [ 0.3626  1.3502 -0.5549]]\n",
      "Epoch 24\n",
      "[[ 0.2787  1.3451  0.5344]\n",
      " [ 1.173   0.4611 -1.1524]] \n",
      "\n",
      " [[ 1.6324 -1.0347  1.8664]\n",
      " [ 0.2953  1.2917 -0.5897]]\n",
      "Epoch 25\n",
      "[[ 0.2675  1.3372  0.521 ]\n",
      " [ 1.1885  0.472  -1.1338]] \n",
      "\n",
      " [[ 1.6422 -1.0263  1.8715]\n",
      " [ 0.2251  1.2309 -0.6268]]\n",
      "Epoch 26\n",
      "[[ 0.2562  1.3294  0.5075]\n",
      " [ 1.2048  0.4833 -1.1143]] \n",
      "\n",
      " [[ 1.6512 -1.0185  1.8764]\n",
      " [ 0.1525  1.1684 -0.6659]]\n",
      "Epoch 27\n",
      "[[ 0.2452  1.3217  0.4943]\n",
      " [ 1.2216  0.4951 -1.0941]] \n",
      "\n",
      " [[ 1.6597 -1.0112  1.8811]\n",
      " [ 0.0787  1.105  -0.7066]]\n",
      "Epoch 28\n",
      "[[ 0.2346  1.3142  0.4815]\n",
      " [ 1.2389  0.5072 -1.0733]] \n",
      "\n",
      " [[ 1.6676 -1.0045  1.8856]\n",
      " [ 0.0047  1.0419 -0.7483]]\n",
      "Epoch 29\n",
      "[[ 0.2246  1.3072  0.4695]\n",
      " [ 1.2563  0.5194 -1.0524]] \n",
      "\n",
      " [[ 1.675  -0.9982  1.8898]\n",
      " [-0.068   0.9801 -0.7902]]\n",
      "Epoch 30\n",
      "[[ 0.2153  1.3007  0.4583]\n",
      " [ 1.2736  0.5315 -1.0317]] \n",
      "\n",
      " [[ 1.6818 -0.9924  1.8938]\n",
      " [-0.1381  0.9208 -0.8315]]\n",
      "Epoch 31\n",
      "[[ 0.2068  1.2948  0.4482]\n",
      " [ 1.2904  0.5433 -1.0115]] \n",
      "\n",
      " [[ 1.6883 -0.987   1.8977]\n",
      " [-0.2046  0.8648 -0.8714]]\n",
      "Epoch 32\n",
      "Converged after 32 epochs\n"
     ]
    }
   ],
   "source": [
    "W1, W2 = multilayer_perceptron(X1, X2, W1, W2, t, 0.5, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final weight vector:\n",
      "W1: [[ 0.2068  1.2948  0.4482]\n",
      " [ 1.2904  0.5433 -1.0115]]\n",
      "W2: [[ 1.6883 -0.987   1.8977]\n",
      " [-0.2046  0.8648 -0.8714]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Final weight vector:\")\n",
    "print(\"W1:\", W1)\n",
    "print(\"W2:\", W2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
